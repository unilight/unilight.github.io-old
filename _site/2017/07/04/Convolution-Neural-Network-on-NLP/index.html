<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><title> &middot; Unilight</title><meta name="description" content=" 之前上李宏毅老師的Machine Learning時，他只有提到2D的CNN。但在HW5時有看到網路上有把1D CNN做在NLP task上，拿來做在那次的作業上發現成效很好。當時便很好奇到底1D CNN的原理是什麼，於是這次就來好好介紹一番。以下的來源基本上都是以下文章的翻譯(笑)：Understanding Convolutional Neural Networks for NLP "> <!--[if gt IE 8]><!----><style> article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}template{display:none}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html,body{margin:0;padding:0}html{line-height:1.65}body{color:#515151;background-color:#fff}a{text-decoration:none}img{display:block;max-width:100%;margin:0 0 1rem}img.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem);margin-left:calc(-1rem);margin-right:calc(-1rem)}h1,h2,h3,h4,h5,h6{margin-bottom:.5rem;font-weight:600;line-height:1.25;color:#313131;text-rendering:optimizeLegibility}h1{font-size:2rem}h2{margin-top:1rem;font-size:1.5rem}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.25rem;font-weight:300}ul,ol,dl{margin-top:0;margin-bottom:1rem}hr{position:relative;margin:1.5rem 0;border:0;border-top:1px solid #eee;border-bottom:1px solid #fff}.container{max-width:38rem;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto}.page-title,.post-title{color:#303030}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-.25rem;margin-bottom:1rem;color:#9a9a9a;font-weight:bold}.related{padding-top:2rem;padding-bottom:2rem}.related-posts{padding-left:0;list-style:none}.related-posts>li{margin-top:1rem}.related-posts>li>*{font-weight:normal}.message{margin-bottom:1rem;padding:1rem;color:#717171;background-color:#f9f9f9;margin-left:-1rem;margin-right:-1rem}body{padding-left:0.5rem}@media (min-width: 48em){html{font-size:16px}body{padding-left:0}}@media (min-width: 58em){html{font-size:18px}}.sr-only{display:none}.backdrop{display:none}.sidebar{position:relative;z-index:4;padding:2rem 1rem;color:rgba(255,255,255,0.75);background-color:#202020;text-align:left;background-size:cover;background-position:center center;min-height:640px;min-height:100vh;margin-left:-0.5rem}.sidebar a{color:#fff}.sidebar ul{list-style:none;padding-left:0}.sidebar-sticky{position:absolute;right:1rem;bottom:1rem;left:1rem}.sidebar-about>h1{color:#fff;font-size:2rem}.sidebar-nav-item{font-weight:bold;display:block;line-height:1.75;padding:.25rem .1rem;border-top:1px solid rgba(255,255,255,0.23)}.sidebar-social>ul{min-height:3.5rem}.sidebar::before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background:rgba(32,32,32,0.33);background:-moz-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:-webkit-linear-gradient(bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%);background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%)}@media (min-width: 48em){.sidebar{position:fixed;top:0;left:0;bottom:0;width:18rem;margin-left:0}}.menu{display:block;padding:1.25rem 1.5rem;color:#9a9a9a;border-bottom:none;position:fixed;top:0;left:0;z-index:2}@media (min-width: 48em){.menu{position:absolute;left:-9999px}}@media (min-width: 48em){.menu:focus{left:19.5rem}}@media (min-width: 64em){.menu:focus{left:21.5rem}}.content{padding-top:4rem;padding-bottom:4rem}@media (min-width: 48em){.content{max-width:38rem;margin-left:20rem;margin-right:2rem;border-left:none}}@media (min-width: 64em){.content{margin-left:22rem;margin-right:4rem}}.me{float:right;width:6.5rem;margin-top:-4.8rem;margin-left:1rem;border-radius:100%;position:relative}@media (min-width: 38em){.me{width:7rem;margin-top:-5.05rem}}@media (min-width: 48em){.me{width:6.5rem;margin-top:-4.8rem}}@media (min-width: 58em){.me{width:7rem;margin-top:-5.05rem}}</style><noscript><link rel="stylesheet" href="/public/css/non-essentials.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700|PT+Serif:400,400italic,700,700italic"><link rel="stylesheet" href="/public/css/icons.css"> </noscript><link rel="preload" href="/public/css/non-essentials.css" as="style" onload="this.rel='stylesheet'"><style> html { font-family: "PT Serif", Georgia, serif; } :focus { outline-color: #A85641; } .font-accent { font-family: "Roboto Slab", "PT Serif", Georgia, serif; } .content a, .related-posts li a:hover { color: #A85641; } ::selection { color: #fff; background: #A85641; } ::-moz-selection { color: #fff; background: #A85641; } .sidebar { background-image: url('/public/img/jb.jpg'); }</style><!--<![endif]--><link rel="canonical" href="http://localhost:4000/2017/07/04/Convolution-Neural-Network-on-NLP/" /><link rel="alternate" type="application/atom+xml" title="Unilight Atom Feed" href="/atom.xml"> <script>!function(n,e){function t(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function o(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}n.isReady=!1,n.loadJSDeferred=function(a,r){function d(){n.isReady=!0;var d=e.createElement("script");d.src=a,r&&(("onload"in d?t:o)(d,r),d.onload||t(d,r));var i=e.getElementsByTagName("script")[0];i.parentNode.insertBefore(d,i)}n.isReady?d():n.addEventListener?n.addEventListener("load",d,!1):n.attachEvent?n.attachEvent("onload",d):n.onload=d}}(window,document); </script> <!--[if lt IE 9]> <script src="https://unpkg.com/html5shiv/dist/html5shiv.min.js"></script> <![endif]--><body> <span class="sr-only">Jump to:</span> <a id="_menu" class="menu" href="#_asidebar"> <span>☰</span> <span class="sr-only">Menu</span> </a><main class="content container" role="main"><article id="post-2017/07/04/Convolution-Neural-Network-on-NLP" class="post" role="article"><h1 class="post-title"> [Deep Learning] Convolution Neural Network on NLP</h1><div class="post-date"> <time datetime="2017-07-04T10:16:00+08:00">07/04/17</time> <span>on <a href="/tag/deeplearning/">Deep Learning</a></span></div><hr/><blockquote><p>之前上李宏毅老師的Machine Learning時，他只有提到2D的CNN。但在HW5時有看到網路上有把1D CNN做在NLP task上，拿來做在那次的作業上發現成效很好。當時便很好奇到底1D CNN的原理是什麼，於是這次就來好好介紹一番。以下的來源基本上都是以下文章的翻譯(笑)：<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/">Understanding Convolutional Neural Networks for NLP</a></blockquote><h2 id="cnn的兩大特色">CNN的兩大特色</h2><p>以下就2D CNN來解釋這兩大特色的intuition。<h5 id="location-invariance">Location Invariance</h5><p>假設我們想要做image classification(或object detection)，想要知道圖片裡面有沒有一隻大象。在做convolution時我們會把filter掃過整張圖，因此我們不在乎到底大象出現在圖片的哪個地方，只要圖片裡有大象就好。<h5 id="compositionality">Compositionality</h5><p>每個filter都是機器理解input(圖片)的小小元件，讓機器可以從low level的特徵(feature)去組織high level的概念。以圖像而言，機器會從像素組成邊邊角角，從邊邊角角組成基本幾何形狀，再從幾何形狀組成一個個的object。這也是為什麼CNN在電腦視覺上這麼強大。<h2 id="如何將cnn應用於nlp">如何將CNN應用於NLP？</h2><p>在NLP中，input data通常是句子或者文章，用matrix表示。每一列會代表一個<em>token</em>，我將它理解成最小文字單位，這是可以自己決定的，通常是單字，但也可以是字母。通常每一列會是一個vector，代表該token的<em>word embedding</em>。因此假設我們有一個10個字的句子，每個字用一個100維的vector表示，則我們會得到一個10x100的「圖片」。 在影像上做convolution時，我們通常會掃完一列之後就換行掃下一列。但在NLP上，我們通常只會掃一個方向，也就是說以上述的10x100「圖片」而言，我們會設filter的形狀為<code class="MathJax_Preview">(region\;size)\times 100</code><script type="math/tex">(region\;size)\times 100</script>，然後由上掃到下。這大概是為什麼這種CNN被稱為1D CNN。這裡的region size也是可以自己調的，但通常是2-5。 看到這裡不禁想問，那前面提到的兩大CNN特色呢？在這裡有得到實現嗎？看起來似乎不然。<ul><li><strong>Location Invariance:</strong> 我們的確會很在乎單字出現在哪，這會大大影響詞性和意思。<li><strong>Compositionality:</strong> 的確，某些字的組合會代表某些意義，例如形容詞修飾名詞，組合出一個帶有特色的名詞。但這種文字上的小元件到底能否像圖片一樣，從像素組成high level的概念，似乎有點說不太通。 這樣看來，比起CNN，較類似於人腦處理語言的RNN，似乎更適合做在NLP上？但出乎意料的，CNN在NLP一直都取得了不錯的成效。就像Bag-of-word模型，雖然有一些錯誤的假設，但已經被應用行之有年且都有很棒的結果。 CNN的一大優點是計算速度相當快，歸功於GPU的發展。和RNN, n-gram相比，CNN不僅速度快，某種程度上也能夠讓filter學到不錯的representation。直覺上，CNN的第一層layer學到的東西與n-gram相當類似。</ul><h2 id="cnn-hyperparemeters">CNN Hyperparemeters</h2><h5 id="narrow-vs-wide-convolution">Narrow vs. Wide convolution</h5><p>當遇到邊緣時，narrow convolution會避開，wide convolution則是做padding，也就是將input以外沒有值的地方以0計算。以下是一個1D的例子<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png" alt="img" /> <em>Source: A Convolutional Neural Network for Modelling Sentences (2014)</em><p>可以發現當filter size很大時，若做narrow convolution，會得到很少的值，以上圖來說，便只得到<code class="MathJax_Preview">(7-5)+1=3</code><script type="math/tex">(7-5)+1=3</script>個output。但如果做wide convolution，則會得到<code class="MathJax_Preview">(7+2*4-5)+1=11</code><script type="math/tex">(7+2*4-5)+1=11</script>個output。透過這個方法，通常可以得到跟input size相同，甚至是更多的output。<h5 id="stride-size">Stride Size</h5><p>這決定了每次掃filter時要移動多少，stride size越大，output size越小。一般而言，標準的stride size都是1。 <img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM.png" alt="img" /> <em>Source: http://cs231n.github.io/convolutional-networks/</em><h5 id="pooling-layers">Pooling Layers</h5><p>Pooling常常跟在convolution後，會將input做subsampling，通常最常見的是max pooling。Pooling的window也是可以自己調的，但在NLP中通常會對整個input做pooling，得到一個scalar作為output。 Pooling有以下好處：<ul><li><strong>保持output size固定:</strong> 舉例來說，如果今天有1000個filter，然後對每個filter做max pooling，則會得到一個1000維的output。這麼一來，output size和filter、input的大小便無關，便可以很有彈性的吃不同size的input。這對classification是很重要的，因為classification常常會需要處理input size不一的資料。<li><strong>降低維度，保留資訊:</strong> 可以將每個filter想成在偵測某種特徵，例如包含某個片語。如果該片語出現在句子中某處，則將該filter和該處做convolution後應該會得到一個很大的值，反之則會得到很小的值。做max pooling後，「該特徵是否出現在句子中的某處」的資訊會留下；但相反的，「該特徵出現在句子中的哪裡」的資訊則會被丟掉。我個人認為這有好有壞。</ul><h5 id="channels">Channels</h5><p>Channel就很像資料的不同「view」。以影像為例，RGB便是三個不同的channel，我們可以對不同的channel做不同的convolution，給予不同的權重。在NLP上，可以用不同的word embedding、語言、理解方式作為不同的channel。<h2 id="conclusion">Conclusion</h2><p>我個人的感想是，CNN除了計算速度相對快，特色是能夠從資料抽出某些特徵，但會流失那些特徵的局部性，也就是不知道那些特徵出現在哪裡。這對NLP的某些task當然是相當有利的，但不代表可以做在所有的task上。還是得要先評估看看該task有什麼特性，再決定要不要使用。</article><aside class="author" role="complementary"><h2>About</h2><img class="me" alt="Unilight Huang" src="/public/img/Bio.jpg" srcset="/public/img/Bio.jpg 2x" /><p>嗨，我是黃奕光 a.k.a. 黃文勁。 我來自台灣的台北市。 我目前就讀於台灣大學資訊工程學系三年級。 我也是一位Locker.</aside><aside class="related" role="complementary"><h2>Related Posts</h2><ul class="related-posts"></ul></aside></main><div id="_backdrop" class="backdrop"></div><header id="_sidebar" class="sidebar" role="banner"><div id="_asidebar" class="container sidebar-sticky"><div class="sidebar-about"><h1 class="font-accent"><a href="/">Unilight</a></h1><p>Locker, Coder, Thinker</div><nav class="sidebar-nav font-accent" role="navigation"><ul><li> <a class="sidebar-nav-item " href="/tag/locking/">Locking</a><li> <a class="sidebar-nav-item " href="/tag/gametheory/">Game Theory</a><li> <a class="sidebar-nav-item " href="/tag/courses/">Courses</a><li> <a class="sidebar-nav-item " href="/tag/deeplearning/">Deep Learning</a><li> <a class="sidebar-nav-item " href="/about/">About</a></ul></nav><div class="sidebar-social"><ul><li> <a href="https://facebook.com/yi.zheng.395"> <span class="icon-facebook"></span> <span class="sr-only">facebook</span> </a><li> <a href="https://www.youtube.com/channel/UCVF6X3gMCDZjxPAGZ-He7RQ"> <span class="icon-youtube"></span> <span class="sr-only">youtube</span> </a><li> <a href="https://github.com/unilight"> <span class="icon-github"></span> <span class="sr-only">github</span> </a></ul></div></div></header><!--[if gt IE 8]><!----> <script>loadJSDeferred('/public/js/hydejack.min.js')</script> <script> WebFontConfig = { google: { families: 'Roboto+Slab:700|PT+Serif:400,400italic,700,700italic'.split('|') }, custom: { families: ['icomoon'], urls: ['/public/css/icons.css'] }, classes: false, events: false }; </script> <script>loadJSDeferred('https://ajax.googleapis.com/ajax/libs/webfont/1.6.16/webfont.js')</script> <!--<![endif]-->
